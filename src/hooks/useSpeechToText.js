// src/hooks/useSpeechToText.js
import { useState, useRef, useCallback, useEffect } from 'react';

export const useSpeechToText = (options = {}) => {
  const {
    language: defaultLanguage = 'fa-IR',
    continuous = true,
    interimResults = true
  } = options;

  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [error, setError] = useState(null);
  const [language, setLanguage] = useState(defaultLanguage);
  const recognitionRef = useRef(null);
  const finalTranscriptRef = useRef('');

  // Ù„ÛŒØ³Øª Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡
  const supportedLanguages = [
    { code: 'fa-IR', name: 'ÙØ§Ø±Ø³ÛŒ', flag: 'ðŸ‡®ðŸ‡·' },
    { code: 'en-US', name: 'English', flag: 'ðŸ‡ºðŸ‡¸' },
    { code: 'en-GB', name: 'English (UK)', flag: 'ðŸ‡¬ðŸ‡§' },
    { code: 'ar-SA', name: 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', flag: 'ðŸ‡¸ðŸ‡¦' },
    { code: 'tr-TR', name: 'TÃ¼rkÃ§e', flag: 'ðŸ‡¹ðŸ‡·' }
  ];

  const resetTranscript = useCallback(() => {
    setTranscript('');
    finalTranscriptRef.current = '';
    setError(null);
  }, []);

  const startListening = useCallback((lang = language) => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      setError('Ù…Ø±ÙˆØ±Ú¯Ø± Ø´Ù…Ø§ Ø§Ø² ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø± Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø§Ø² Chrome ÛŒØ§ Edge Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.');
      return;
    }

    resetTranscript();

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    
    recognition.continuous = continuous;
    recognition.interimResults = interimResults;
    recognition.lang = lang;
    recognition.maxAlternatives = 1;

    let final = '';
    let interim = '';

    recognition.onstart = () => {
      setIsListening(true);
      setError(null);
      console.log(`Speech recognition started in ${lang}`);
    };

    recognition.onresult = (event) => {
      interim = '';
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        const text = result[0].transcript.trim();
        
        if (result.isFinal) {
          final += text + ' ';
          interim = '';
        } else {
          interim = text;
        }
      }

      if (final) {
        finalTranscriptRef.current += final;
        setTranscript(finalTranscriptRef.current + interim);
        final = '';
      } else if (interim) {
        setTranscript(finalTranscriptRef.current + interim);
      }
    };

    recognition.onerror = (event) => {
      console.error('Speech recognition error:', event.error);
      
      switch (event.error) {
        case 'not-allowed':
          if (event.message.includes('HTTP')) {
            setError('Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø±ØŒ Ø§Ø² HTTPS ÛŒØ§ localhost Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯');
          } else {
            setError('Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ù…Ø¬Ø§Ø² Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§ Ù…Ø¬ÙˆØ² Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.');
          }
          break;
        case 'network':
          setError('Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø±');
          break;
        case 'language-not-supported':
          setError('Ø²Ø¨Ø§Ù† Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯');
          break;
        case 'audio-capture':
          setError('Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª');
          break;
        default:
          setError(`Ø®Ø·Ø§ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø±: ${event.error}`);
      }
      
      setIsListening(false);
    };

    recognition.onend = () => {
      setIsListening(false);
      if (interim) {
        finalTranscriptRef.current += interim + ' ';
        setTranscript(finalTranscriptRef.current);
      }
    };

    recognitionRef.current = recognition;
    
    try {
      recognition.start();
    } catch (error) {
      setError('Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø±');
      console.error('Recognition start error:', error);
    }
  }, [continuous, interimResults, language, resetTranscript]);

  const stopListening = useCallback(() => {
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (error) {
        console.error('Error stopping recognition:', error);
      }
      setIsListening(false);
    }
  }, []);

  const changeLanguage = useCallback((newLanguage) => {
    setLanguage(newLanguage);
    if (isListening) {
      stopListening();
      setTimeout(() => startListening(newLanguage), 100);
    }
  }, [isListening, startListening, stopListening]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, []);

  return {
    isListening,
    transcript,
    error,
    language,
    supportedLanguages,
    startListening,
    stopListening,
    resetTranscript,
    changeLanguage
  };
};